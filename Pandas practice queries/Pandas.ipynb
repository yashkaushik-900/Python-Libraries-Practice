{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5efea7c-70df-4b54-aae0-584d1298ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Salary\n",
      "0   John   25  300000\n",
      "1  Peter   28   45000\n",
      "2   Lisa   31   25000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"Name\": [\"John\", \"Peter\", \"Lisa\"],\n",
    "        \"Age\":[25,28,31],\n",
    "        \"Salary\": [300000,45000,25000]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6479ed-4adf-4cb5-a846-5b42c34f978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Name gender  salary\n",
      "0           0    ayushi      F   20000\n",
      "1           1     rohit      M   25000\n",
      "2           2  pranjali      F   27000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:/All Files/Data Analysis/Python libraries/Pandas practice queries/company.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e4348fd-bea1-4f9d-b558-6eeba809f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    order_details_id  order_id order_date   order_time  item_id  Mode\n",
      "0                  1         1   1/1/2023  11:38:36 AM    109.0  CASH\n",
      "1                  2         2   1/1/2023  11:57:40 AM    108.0  CASH\n",
      "2                  3         2   1/1/2023  11:57:40 AM    124.0   UPI\n",
      "3                  4         2   1/1/2023  11:57:40 AM    117.0   UPI\n",
      "4                  5         2   1/1/2023  11:57:40 AM    129.0   UPI\n",
      "5                  6         2   1/1/2023  11:57:40 AM    106.0  CASH\n",
      "6                  7         3   1/1/2023  12:12:28 PM    117.0   UPI\n",
      "7                  8         3   1/1/2023  12:12:28 PM    119.0   UPI\n",
      "8                  9         4   1/1/2023  12:16:31 PM    117.0   UPI\n",
      "9                 10         5   1/1/2023  12:21:30 PM    117.0   UPI\n",
      "10                11         6   1/1/2023  12:29:36 PM    101.0  CASH\n",
      "11                12         6   1/1/2023  12:29:36 PM    114.0   UPI\n",
      "12                13         7   1/1/2023  12:50:37 PM    123.0   UPI\n",
      "13                14         8   1/1/2023  12:51:37 PM    123.0   UPI\n",
      "14                15         9   1/1/2023  12:52:01 PM    108.0  CASH\n",
      "15                16         9   1/1/2023  12:52:01 PM    126.0   UPI\n",
      "16                17         9   1/1/2023  12:52:01 PM    110.0  CASH\n",
      "17                18         9   1/1/2023  12:52:01 PM    117.0   UPI\n",
      "18                19         9   1/1/2023  12:52:01 PM    117.0   UPI\n",
      "19                20         9   1/1/2023  12:52:01 PM    129.0   UPI\n",
      "20                21         9   1/1/2023  12:52:01 PM    122.0   UPI\n",
      "21                22         9   1/1/2023  12:52:01 PM    130.0   UPI\n",
      "22                23         9   1/1/2023  12:52:01 PM    132.0   UPI\n",
      "23                24        10   1/1/2023   1:00:15 PM    129.0   UPI\n",
      "24                25        10   1/1/2023   1:00:15 PM    105.0  CASH\n",
      "25                26        11   1/1/2023   1:02:59 PM    101.0  CASH\n",
      "26                27        11   1/1/2023   1:02:59 PM    102.0  CASH\n",
      "27                28        11   1/1/2023   1:02:59 PM    102.0  CASH\n",
      "28                29        11   1/1/2023   1:02:59 PM    113.0   UPI\n",
      "29                30        12   1/1/2023   1:04:41 PM    102.0  CASH\n",
      "30                31        12   1/1/2023   1:04:41 PM    102.0  CASH\n",
      "31                32        12   1/1/2023   1:04:41 PM    104.0  CASH\n",
      "32                33        12   1/1/2023   1:04:41 PM    117.0   UPI\n",
      "33                34        13   1/1/2023   1:11:55 PM    129.0   UPI\n",
      "34                35        14   1/1/2023   1:14:19 PM    114.0   UPI\n",
      "35                36        15   1/1/2023   1:33:00 PM    107.0  CASH\n",
      "36                37        15   1/1/2023   1:33:00 PM    124.0   UPI\n",
      "37                38        15   1/1/2023   1:33:00 PM    121.0   UPI\n",
      "38                39        15   1/1/2023   1:33:00 PM    114.0   UPI\n",
      "39                40        16   1/1/2023   1:34:07 PM    125.0   UPI\n",
      "40                41        16   1/1/2023   1:34:07 PM    111.0   UPI\n",
      "41                42        16   1/1/2023   1:34:07 PM    106.0  CASH\n",
      "42                43        17   1/1/2023   1:53:00 PM    101.0  CASH\n",
      "43                44        17   1/1/2023   1:53:00 PM    116.0   UPI\n",
      "44                45        17   1/1/2023   1:53:00 PM    124.0   UPI\n",
      "45                46        17   1/1/2023   1:53:00 PM    125.0   UPI\n",
      "46                47        17   1/1/2023   1:53:00 PM    117.0   UPI\n",
      "47                48        17   1/1/2023   1:53:00 PM    127.0   UPI\n",
      "48                49        17   1/1/2023   1:53:00 PM    128.0   UPI\n",
      "49                50        17   1/1/2023   1:53:00 PM    129.0   UPI\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:/All Files/Data Analysis/Python libraries/Pandas practice queries/order_details.csv\")\n",
    "print(data.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125dd96-a1cf-463b-b433-e64dee09265c",
   "metadata": {},
   "source": [
    "# Exploring data in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ec6f6fc-75dc-4439-bc0a-3a1ef15c4408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n",
      "       EEID          Full Name             Job Title       Department  \\\n",
      "990  E01578       Anthony Hong            Sr. Manger               IT   \n",
      "991  E03430        Leo Herrera  Sr. Business Partner  Human Resources   \n",
      "992  E03058      Robert Wright   Technical Architect               IT   \n",
      "993  E04762  Audrey Richardson              Director               IT   \n",
      "994  E01148     Scarlett Kumar       Systems Analyst               IT   \n",
      "995  E03094       Wesley Young           Sr. Analyst        Marketing   \n",
      "996  E01909       Lillian Khan               Analyst          Finance   \n",
      "997  E04398        Oliver Yang              Director        Marketing   \n",
      "998  E02521        Lily Nguyen           Sr. Analyst          Finance   \n",
      "999  E03545        Sofia Cheng        Vice President       Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "990  Research & Development    Male      Asian   37 2010-11-29         146961   \n",
      "991  Research & Development    Male     Latino   48 1998-04-22          85369   \n",
      "992           Manufacturing    Male  Caucasian   30 2015-06-14          67489   \n",
      "993           Manufacturing  Female  Caucasian   46 2018-10-06         166259   \n",
      "994               Corporate  Female      Asian   55 2009-01-07          47032   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country      City  Exit Date  \n",
      "990     0.11  United States  Columbus        NaT  \n",
      "991     0.00         Brazil    Manaus 2004-11-27  \n",
      "992     0.00  United States   Chicago        NaT  \n",
      "993     0.17  United States   Chicago        NaT  \n",
      "994     0.00  United States  Columbus        NaT  \n",
      "995     0.00  United States  Columbus        NaT  \n",
      "996     0.00          China   Chengdu 2018-01-08  \n",
      "997     0.15  United States     Miami        NaT  \n",
      "998     0.00          China   Chengdu        NaT  \n",
      "999     0.31  United States     Miami        NaT  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"D:/All Files/Data Analysis/Python libraries/Pandas practice queries/ESD.xlsx\")\n",
    "print(data.head(10))\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57fb4386-e37c-43b4-b2d5-bdbaca0b337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   EEID           1000 non-null   object        \n",
      " 1   Full Name      1000 non-null   object        \n",
      " 2   Job Title      1000 non-null   object        \n",
      " 3   Department     1000 non-null   object        \n",
      " 4   Business Unit  1000 non-null   object        \n",
      " 5   Gender         1000 non-null   object        \n",
      " 6   Ethnicity      1000 non-null   object        \n",
      " 7   Age            1000 non-null   int64         \n",
      " 8   Hire Date      1000 non-null   datetime64[ns]\n",
      " 9   Annual Salary  1000 non-null   int64         \n",
      " 10  Bonus %        1000 non-null   float64       \n",
      " 11  Country        1000 non-null   object        \n",
      " 12  City           1000 non-null   object        \n",
      " 13  Exit Date      85 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(9)\n",
      "memory usage: 109.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# to getting information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "814e4919-2137-4986-a278-65f0745311f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Annual Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "      <th>Exit Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.382000</td>\n",
       "      <td>2012-04-07 02:54:14.400000</td>\n",
       "      <td>113217.365000</td>\n",
       "      <td>0.088660</td>\n",
       "      <td>2016-11-02 18:04:14.117647104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>1992-01-09 00:00:00</td>\n",
       "      <td>40063.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994-12-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2007-02-14 00:00:00</td>\n",
       "      <td>71430.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-12-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>2014-02-15 12:00:00</td>\n",
       "      <td>96557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-05-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>2018-06-22 00:00:00</td>\n",
       "      <td>150782.250000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>2021-04-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>2021-12-26 00:00:00</td>\n",
       "      <td>258498.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.246981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53545.985644</td>\n",
       "      <td>0.117856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age                   Hire Date  Annual Salary      Bonus %  \\\n",
       "count  1000.000000                        1000    1000.000000  1000.000000   \n",
       "mean     44.382000  2012-04-07 02:54:14.400000  113217.365000     0.088660   \n",
       "min      25.000000         1992-01-09 00:00:00   40063.000000     0.000000   \n",
       "25%      35.000000         2007-02-14 00:00:00   71430.250000     0.000000   \n",
       "50%      45.000000         2014-02-15 12:00:00   96557.000000     0.000000   \n",
       "75%      54.000000         2018-06-22 00:00:00  150782.250000     0.150000   \n",
       "max      65.000000         2021-12-26 00:00:00  258498.000000     0.400000   \n",
       "std      11.246981                         NaN   53545.985644     0.117856   \n",
       "\n",
       "                           Exit Date  \n",
       "count                             85  \n",
       "mean   2016-11-02 18:04:14.117647104  \n",
       "min              1994-12-18 00:00:00  \n",
       "25%              2014-12-25 00:00:00  \n",
       "50%              2019-05-23 00:00:00  \n",
       "75%              2021-04-09 00:00:00  \n",
       "max              2022-08-17 00:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c2918c-82ef-4e97-875e-26677bdebc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID               0\n",
      "Full Name          0\n",
      "Job Title          0\n",
      "Department         0\n",
      "Business Unit      0\n",
      "Gender             0\n",
      "Ethnicity          0\n",
      "Age                0\n",
      "Hire Date          0\n",
      "Annual Salary      0\n",
      "Bonus %            0\n",
      "Country            0\n",
      "City               0\n",
      "Exit Date        915\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to checking null values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c4c1ab-b8e6-468e-859c-5eb57a049699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# Dealing with Duplicate value by Pandas\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"company1.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b86ffdee-8a1e-4710-ad21-f982847e5717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# identify duplicate\n",
    "print(data[\"EEID\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97e1e5c9-6a26-415f-9df2-7342c228de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "4  EMP05       NaN      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data.drop_duplicates(\"Name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd6ee0-44e0-4fd8-b9b7-0b974d99e7b1",
   "metadata": {},
   "source": [
    "# working with missing data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53cb876a-18d7-4664-acfd-0b8a8a778601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"company1.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0db01e0-5dd1-45c4-af35-ef04c455d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fa4cd2e-ae40-4420-806d-634c4d3d9589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID    Name gender   salary\n",
      "1  EMP02   rohit      M  25000.0\n",
      "3  EMP01  ayushi      F  20000.0\n",
      "6  EMP02   rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3ed8b6a-5254-469c-980d-19b9828c1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "943d77c3-f2da-42f2-9371-5a67483f17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  30000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali  30000  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05     30000      M  25000.0\n",
      "5  EMP06     rohit      M  30000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(data.replace(np.nan, 30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb65d9ed-a61e-4460-b3a5-0955ad19ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n",
      "24400.0\n"
     ]
    }
   ],
   "source": [
    "data[\"salary\"] = data[\"salary\"].replace(np.nan, 24400)\n",
    "print(data)\n",
    "print(data[\"salary\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12fa33b6-aeaf-49fa-bf65-c7676c88698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ec5316c-09ee-478f-bea4-6d7ec7a7a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      F  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05     rohit      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3736\\3869959467.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(data.fillna(method = \"bfill\"))\n"
     ]
    }
   ],
   "source": [
    "# using forward and backward filled\n",
    "print(data.fillna(method = \"bfill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "413ac627-52b8-47c4-8918-439c48e07027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      M  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05    ayushi      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_3736\\1391920301.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(data.fillna(method = \"ffill\"))\n"
     ]
    }
   ],
   "source": [
    "print(data.fillna(method = \"ffill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "799419e5-394e-4c46-956d-56fb34d28580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali     hi  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05        hi      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "print(data.fillna(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a68621a-942b-492d-87fe-432edb29a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24400.0\n"
     ]
    }
   ],
   "source": [
    "print(data[\"salary\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617422f0-ea33-4de9-99fe-f21b14dd5c5a",
   "metadata": {},
   "source": [
    "## Columns Transformation in Pandas (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04905727-bcc4-438d-b4d1-f1aefe3421e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n",
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date GetsBonus GetBonus  \n",
      "0     0.15  United States    Seattle 2021-10-16       NaN    bonus  \n",
      "1     0.00          China  Chongqing        NaT  no bonus      NaN  \n",
      "2     0.20  United States    Chicago        NaT       NaN    bonus  \n",
      "3     0.07  United States    Chicago        NaT       NaN    bonus  \n",
      "4     0.00  United States    Phoenix        NaT  no bonus      NaN  \n",
      "5     0.00          China  Chongqing        NaT  no bonus      NaN  \n",
      "6     0.10  United States    Phoenix        NaT       NaN    bonus  \n",
      "7     0.00  United States      Miami 2021-05-20  no bonus      NaN  \n",
      "8     0.06  United States     Austin        NaT       NaN    bonus  \n",
      "9     0.00  United States    Chicago        NaT  no bonus      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"ESD.xlsx\")\n",
    "print(data)\n",
    "\n",
    "df.loc[(df[\"Bonus %\"]==0), \"GetsBonus\"] = \"no bonus\"\n",
    "df.loc[(df[\"Bonus %\"]>0, \"GetBonus\")] = \"bonus\"\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1636eb8-e8a9-41e5-bc5a-d2b13712aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'First Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'First Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m data = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mESD.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.head(\u001b[32m10\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mFull Name\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFirst Name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.str.capitalize()  +\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m +  data[\u001b[33m\"\u001b[39m\u001b[33mLast Name\u001b[39m\u001b[33m\"\u001b[39m].str.capitalize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'First Name'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"ESD.xlsx\")\n",
    "print(data.head(10))\n",
    "\n",
    "data[\"Full Name\"] = data[\"First Name\"].str.capitalize()  +\"  \" +  data[\"Last Name\"].str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a862-e3dd-4490-aa03-e31c07075db0",
   "metadata": {},
   "source": [
    "## Columns Transformation in Pandas Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e4ade34-4482-46f1-a086-bc1e00a93ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date    Category       Sub-Category   Amount Payment Mode\n",
      "0 2023-01-01     Grocery             Grocery      30         Cash\n",
      "1 2023-01-02        Food          Restaurant     890          UPI\n",
      "2 2023-01-04         123              Zomato     257          NaN\n",
      "3 2023-01-06  Essentials               Diary     120          UPI\n",
      "4 2023-01-06  Essentials             Perfume    1500         Cash\n",
      "5 2023-01-09     Grocery  Fruits and Veggies     456         Cash\n",
      "6 2023-01-10       Bills          House Rent   16000          UPI\n",
      "7 2023-01-10     Grocery      Tomato KetchUp      70          UPI\n",
      "8 2023-01-12        Food                Chai      15          UPI\n",
      "9 2023-01-15  Essentials      Salt and Sugar      50          NaN\n",
      "        Date    Category       Sub-Category   Amount Payment Mode   Bonus\n",
      "0 2023-01-01     Grocery             Grocery      30         Cash    1.50\n",
      "1 2023-01-02        Food          Restaurant     890          UPI   44.50\n",
      "2 2023-01-04         123              Zomato     257          NaN   12.85\n",
      "3 2023-01-06  Essentials               Diary     120          UPI    6.00\n",
      "4 2023-01-06  Essentials             Perfume    1500         Cash   75.00\n",
      "5 2023-01-09     Grocery  Fruits and Veggies     456         Cash   22.80\n",
      "6 2023-01-10       Bills          House Rent   16000          UPI  800.00\n",
      "7 2023-01-10     Grocery      Tomato KetchUp      70          UPI    3.50\n",
      "8 2023-01-12        Food                Chai      15          UPI    0.75\n",
      "9 2023-01-15  Essentials      Salt and Sugar      50          NaN    2.50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"expense3.xlsx\")\n",
    "print(data.head(10))\n",
    "data[\"Bonus\"] = (data[\"Amount\"]/100)*5\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90ec5357-c1ce-4817-b636-aa661762a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Months\n",
      "0   January\n",
      "1  February\n",
      "2     March\n",
      "3     April\n",
      "     Months Short_months\n",
      "0   January          Jan\n",
      "1  February          Feb\n",
      "2     March          Mar\n",
      "3     April          Apr\n"
     ]
    }
   ],
   "source": [
    "data = {\"Months\": [\"January\", \"February\", \"March\", \"April\"]}\n",
    "\n",
    "a = pd.DataFrame(data)\n",
    "print(a)\n",
    "\n",
    "\n",
    "def extract(value):\n",
    "    return value[0:3]\n",
    "\n",
    "a[\"Short_months\"] = a[\"Months\"].map(extract)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497d6a0-965e-4690-8be2-2b67871a9391",
   "metadata": {},
   "source": [
    "## Group by in Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7244aa60-c677-42b5-9317-6bced9172adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"ESD.xlsx\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6283646e-6270-49c5-968c-a0c86b953915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        EEID\n",
      "Department      Gender      \n",
      "Accounting      Female    53\n",
      "                Male      43\n",
      "Engineering     Female    80\n",
      "                Male      78\n",
      "Finance         Female    69\n",
      "                Male      51\n",
      "Human Resources Female    64\n",
      "                Male      61\n",
      "IT              Female   119\n",
      "                Male     122\n",
      "Marketing       Female    57\n",
      "                Male      63\n",
      "Sales           Female    76\n",
      "                Male      64\n"
     ]
    }
   ],
   "source": [
    "gp = data.groupby([\"Department\", \"Gender\"]).agg({\"EEID\": \"count\"})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8c9a5ebb-2fcb-4934-b021-bff471d83266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Annual Salary  Age\n",
      "Country       Gender                    \n",
      "Brazil        Female         258426   25\n",
      "              Male           249506   26\n",
      "China         Female         249686   25\n",
      "              Male           257194   25\n",
      "United States Female         258498   25\n",
      "              Male           258081   25\n"
     ]
    }
   ],
   "source": [
    "gp1 = data.groupby([\"Country\", \"Gender\"]).agg({\"Annual Salary\": \"max\", \"Age\": \"min\"})\n",
    "print(gp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5b488-0d16-457a-a017-8c63fb682f1f",
   "metadata": {},
   "source": [
    "## Merge, Join and Concatenate in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "530ab97f-26bc-4d93-bd4a-675e282c8811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id    Name  Age\n",
      "0    E01     Ram   34\n",
      "1    E02   Shyam   56\n",
      "2    E03   rahul   23\n",
      "3    E04  Vishal   44\n",
      "4    E05    Ravi   32\n",
      "5    E06    John   36\n",
      "\n",
      "  Emp Id  Salary\n",
      "0    E01   45000\n",
      "1    E07   56000\n",
      "2    E03   34000\n",
      "3    E04   30000\n",
      "4    E08   50000\n",
      "5    E06   62000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = {\"Emp Id\": [\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "         \"Name\": [\"Ram\", \"Shyam\", \"rahul\", \"Vishal\", \"Ravi\",\"John\"],\n",
    "         \"Age\": [34,56,23,44,32,36]}\n",
    "data2 = {\"Emp Id\":[\"E01\",\"E07\",\"E03\",\"E04\",\"E08\",\"E06\"],\n",
    "         \"Salary\": [45000,56000,34000,30000,50000,62000]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a3ae87f-afc3-4c5d-968a-636a28c3b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id    Name  Age   Salary\n",
      "0    E01     Ram   34  45000.0\n",
      "1    E02   Shyam   56      NaN\n",
      "2    E03   rahul   23  34000.0\n",
      "3    E04  Vishal   44  30000.0\n",
      "4    E05    Ravi   32      NaN\n",
      "5    E06    John   36  62000.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left = df1,right = df2,on = \"Emp Id\", how=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dcfd3587-2abc-454a-9c67-9b9e698bbc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id    Name   Age  Salary\n",
      "0    E01     Ram  34.0   45000\n",
      "1    E07     NaN   NaN   56000\n",
      "2    E03   rahul  23.0   34000\n",
      "3    E04  Vishal  44.0   30000\n",
      "4    E08     NaN   NaN   50000\n",
      "5    E06    John  36.0   62000\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left = df1,right = df2,on = \"Emp Id\", how=\"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f69b8c83-3a77-40ae-af62-98e54f95ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id    Name   Age  Salary\n",
      "0    E01     Ram  34.0   45000\n",
      "1    E07     NaN   NaN   56000\n",
      "2    E03   rahul  23.0   34000\n",
      "3    E04  Vishal  44.0   30000\n",
      "4    E08     NaN   NaN   50000\n",
      "5    E06    John  36.0   62000\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(left = df1, right = df2, on = \"Emp Id\", how = \"right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d79cc893-777b-43c5-8541-c78320c6a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = {\"Emp Id\": [\"E01\",\"E02\",\"E03\",\"E04\",\"E05\",\"E06\"],\n",
    "         \"Name\": [\"Ram\", \"Shyam\", \"rahul\", \"Vishal\", \"Ravi\",\"John\"],\n",
    "         \"Age\": [34,56,23,44,32,36]}\n",
    "\n",
    "data2 = {\"Emp Id\": [\"E07\",\"E08\",\"E09\",\"E010\",\"E011\",\"E012\"],\n",
    "         \"Name\": [\"bittu\", \"chintu\", \"pappu\", \"chotu\", \"bunty\",\"goly\"],\n",
    "         \"Age\": [34,56,23,44,32,36]}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f1db7696-f2d1-45e7-a8ae-bac07a0ccef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp Id    Name  Age\n",
      "0    E01     Ram   34\n",
      "1    E02   Shyam   56\n",
      "2    E03   rahul   23\n",
      "3    E04  Vishal   44\n",
      "4    E05    Ravi   32\n",
      "5    E06    John   36\n",
      "0    E07   bittu   34\n",
      "1    E08  chintu   56\n",
      "2    E09   pappu   23\n",
      "3   E010   chotu   44\n",
      "4   E011   bunty   32\n",
      "5   E012    goly   36\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f841a3-34d3-48e5-b0ca-7f1492870a63",
   "metadata": {},
   "source": [
    "## Pandas | compare DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cd7ac716-c8fe-49d4-9f8d-cad8c1b9e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fruit  Price  Quantity\n",
      "0   Mango    100        15\n",
      "1  apples    150        10\n",
      "2  banana     50        10\n",
      "3  papaya     35         3\n",
      "    Fruit  Price  Quantity\n",
      "0   Mango    120        12\n",
      "1  apples    175        15\n",
      "2  banana     50        10\n",
      "3  papaya     30         5\n",
      "   Price        Quantity      \n",
      "    self  other     self other\n",
      "0  100.0  120.0     15.0  12.0\n",
      "1  150.0  175.0     10.0  15.0\n",
      "3   35.0   30.0      3.0   5.0\n",
      "   Price        Quantity      \n",
      "    self  other     self other\n",
      "0  100.0  120.0     15.0  12.0\n",
      "1  150.0  175.0     10.0  15.0\n",
      "3   35.0   30.0      3.0   5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict = {\"Fruit\": [\"Mango\",\"apples\", \"banana\",\"papaya\"],\n",
    "        \"Price\": [100,150,50,35],\n",
    "        \"Quantity\": [15,10,10,3]}\n",
    "df1 = pd.DataFrame(dict)\n",
    "print(df1)\n",
    "\n",
    "df2 = df1.copy()\n",
    "\n",
    "df2.loc[0, \"Price\"] = 120\n",
    "df2.loc[1, \"Price\"] = 175\n",
    "df2.loc[3, \"Price\"] = 30\n",
    "df2.loc[0, \"Quantity\"] = 12\n",
    "df2.loc[1, \"Quantity\"] = 15\n",
    "df2.loc[3, \"Quantity\"] = 5\n",
    "\n",
    "print(df2)\n",
    "print(df1.compare(df2))\n",
    "print(df1.compare(df2, keep_shape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2688f-8542-4cb2-8b62-d3585bf9d1e8",
   "metadata": {},
   "source": [
    "## Pandas - Pivoting and Melting DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1a0a7e6f-b024-47e0-bf78-62a90e07cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  keys  Names Houses Grades\n",
      "0   k1   John    red    3rd\n",
      "1   k2    Ben   blue    8th\n",
      "2   k1  David  green    9th\n",
      "3   k2  Peter    red    8th\n",
      "      Houses                   Grades                 \n",
      "Names    Ben  David John Peter    Ben David John Peter\n",
      "keys                                                  \n",
      "k1       NaN  green  red   NaN    NaN   9th  3rd   NaN\n",
      "k2      blue    NaN  NaN   red    8th   NaN  NaN   8th\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict = {\"keys\": [\"k1\",\"k2\",\"k1\",\"k2\"],\n",
    "         \"Names\": [\"John\",\"Ben\",\"David\",\"Peter\"],\n",
    "         \"Houses\": [\"red\",\"blue\",\"green\",\"red\"],\n",
    "         \"Grades\": [\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "print(df)\n",
    "print(df.pivot(index=\"keys\",columns=\"Names\",values=[\"Houses\",\"Grades\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a11067-a573-4d65-a522-89220cab3126",
   "metadata": {},
   "source": [
    "### Melting variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "266c0d85-6e18-4c54-a107-ead83a67729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Names Houses Grades\n",
      "0   John    red    3rd\n",
      "1    Ben   blue    8th\n",
      "2  David  green    9th\n",
      "3  Peter    red    8th\n",
      "   Names Houses&Grades values\n",
      "0   John        Houses    red\n",
      "1    Ben        Houses   blue\n",
      "2  David        Houses  green\n",
      "3  Peter        Houses    red\n"
     ]
    }
   ],
   "source": [
    "dict = { \"Names\": [\"John\",\"Ben\",\"David\",\"Peter\"],\n",
    "         \"Houses\": [\"red\",\"blue\",\"green\",\"red\"],\n",
    "         \"Grades\": [\"3rd\",\"8th\",\"9th\",\"8th\"]}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "print(df)\n",
    "print(pd.melt(df, id_vars=[\"Names\"], value_vars=[\"Houses\"], var_name=\"Houses&Grades\", value_name=\"values\"))\n",
    "# print(df.pivot(index=\"keys\",columns=\"Names\",values=[\"Houses\",\"Grades\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
